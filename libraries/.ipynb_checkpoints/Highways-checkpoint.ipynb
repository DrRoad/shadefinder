{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is used to aggregate the point level sunglare map to street segment for Viz\n",
    "\n",
    "In order to make the viz possible and more beautify, the original point data need to be aggregated to the street segments. In order to make the script more efficient, the rtree will be used to do the anlaysis. The whole procedures are based on the fiona and shapely. There are several steps to do the spatial analysis. \n",
    "\n",
    "--Xiaojiang Li, MIT Senseable City Lab, June 21, 2018\n",
    "\n",
    "1. The first step is to split the original road network into a lot of street segment, considering the orignal road map usually have quite long street segment. \n",
    "\n",
    "2. The second step is to buid rtree index on the segmented street segment in order to make the spatial intersection more efficient.\n",
    "\n",
    "3. The third step is to intersect the street segments on the point data and assign the attributes (sunglare information) to the street segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, os.path\n",
    "import sys\n",
    "import fiona\n",
    "from shapely.geometry import LineString, mapping, shape, Point\n",
    "from shapely.ops import transform, unary_union\n",
    "import rtree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the spatial data with right projection\n",
    "Make sure all spatial data are in the right projection, in this case, we used the local projection of Floridia, with the unit of map is meter (for buffer analysis purpose). It is difficult to process the data with different projections\n",
    "Therefore, you'd better to make the map projections match before the spatial analysis. There are some command line tools and open source software for you to do this, such as QGIS, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # for Florida\n",
    "root1 = r'/Users/senseablecity/Dropbox (MIT)/ResearchProj/SunGlare/NationalScale-sunglare/StreetMaps/FL'\n",
    "# streetMap = os.path.join(root, 'interstates.shp')\n",
    "# # streetMap = os.path.join(root, 'road_reproj.shp')\n",
    "# # streetMap = os.path.join(root, 'sunglare_interstates_test.shp')\n",
    "# sunglareMap = os.path.join(root, 'sunglareMap-6-20_flproj.shp')\n",
    "# outputShp = os.path.join(root, 'sunglare_interstates.shp')\n",
    "\n",
    "sunglareMap = os.path.join(root1, 'sunglareMap-6-20_flproj.shp')\n",
    "\n",
    "root = r'/Users/senseablecity/Dropbox (MIT)/ResearchProj/SunGlare/NationalScale-sunglare/accident data/FL/DOT Data/funclass'\n",
    "streetMap = os.path.join(root, 'sunglare_basemap.shp')\n",
    "outputShp = os.path.join(root, 'sunglare_stateHighway.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the sunglare data and save all the information into a list\n",
    "In order to make the data handeling easier, we'd better to save the attribute of shapefiles into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "glare_records = []\n",
    "fieldlist = ['pntNum', 'panoid', 'hyaw', 'riseglare', 'risedur', 'setglare', 'setdur']\n",
    "\n",
    "with fiona.open(sunglareMap, 'r') as glare:\n",
    "    for feat in glare:\n",
    "        item = {}\n",
    "        for field in fieldlist:\n",
    "            attr = feat['properties'][field]\n",
    "            item.update({field: attr})\n",
    "            \n",
    "#         lon = feat['properties']['longitude']\n",
    "#         lat = feat['properties']['latitude']\n",
    "#         point = Point(float(lon), float(lat))\n",
    "#         print ('The created geom object is:', point)\n",
    "        \n",
    "        # add the point geom to the dictionary\n",
    "        pnt_geom = shape(feat['geometry'])\n",
    "        item.update({'point': pnt_geom})\n",
    "        \n",
    "        glare_records.append(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# glare_records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the roads into shorter lines\n",
    "In order make the result more reasonable, we need to split the long street segment into shorter street segments, cite from https://www.azavea.com/blog/2016/10/05/philippines-road-safety-using-shapely-fiona-locate-high-risk-traffic-areas/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using recursive statement to split longer roads into shorter segments\n",
    "# Reference: https://www.azavea.com/blog/2016/10/05/philippines-road-safety-using-shapely-fiona-locate-high-risk-traffic-areas/\n",
    "\n",
    "def split_line(line, max_line_units):\n",
    "    '''\n",
    "    The input:\n",
    "        line: the LineString object\n",
    "        max_line_units: the split distance, be careful of the units\n",
    "    output:\n",
    "        a list of LineString segment\n",
    "    '''\n",
    "    \n",
    "    if line.length <= max_line_units:\n",
    "        return [line]\n",
    "    \n",
    "    half_length = line.length / 2\n",
    "    coords = list(line.coords)\n",
    "    \n",
    "    for idx, point in enumerate(coords):\n",
    "        proj_dist = line.project(Point(point))\n",
    "        if proj_dist == half_length:\n",
    "            return [LineString(coords[:idx + 1]), LineString(coords[idx:])]\n",
    "        \n",
    "        if proj_dist > half_length:\n",
    "            mid_point = line.interpolate(half_length)\n",
    "            head_line = LineString(coords[:idx] + [(mid_point.x, mid_point.y)])\n",
    "            tail_line = LineString([(mid_point.x, mid_point.y)] + coords[idx:])\n",
    "            return split_line(head_line, max_line_units) + split_line(tail_line, max_line_units)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split lines into shorter street segments, keep the attribute of street\n",
    "This session also output the shorter street segments into a shapefile, although this is not necessary. The returned results will be saved into a list split_lines, which stores all LineString items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/senseablecity/Dropbox (MIT)/ResearchProj/SunGlare/NationalScale-sunglare/accident data/FL/DOT Data/funclass'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "streetMap = os.path.join(root, 'sunglare_basemap.shp')\n",
    "segStreetMap = os.path.join(root, 'shorterStreetSeg_AllRoads.shp')\n",
    "\n",
    "split_lines = []\n",
    "\n",
    "schema_test = {\n",
    "    'geometry': 'LineString',\n",
    "    'properties': {\n",
    "        'length': 'float',\n",
    "        'RouteName': 'str:50'\n",
    "    }\n",
    "}\n",
    "\n",
    "segment_records = []\n",
    "\n",
    "with fiona.open(streetMap, 'r') as streets:\n",
    "    crs = streets.crs\n",
    "    schema = streets.schema.copy()\n",
    "    \n",
    "    with fiona.open(segStreetMap, 'w', driver=\"ESRI Shapefile\", crs=crs, schema=schema_test) as output_segment:\n",
    "        for street in streets:\n",
    "#             RouteName = street['properties']['FULLNAME']\n",
    "            street_geom = shape(street['geometry'])\n",
    "            \n",
    "            street_segments = split_line(street_geom, 5000)\n",
    "            split_lines.extend(street_segments)\n",
    "            \n",
    "            # save the splitted segment to a shapefile\n",
    "            for street_segment in street_segments:\n",
    "                output_segment.write({\n",
    "                    'geometry': mapping(street_segment),\n",
    "                    'properties': {'length':street_segment.length, 'RouteName': RouteName}\n",
    "                })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15713"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build rtree to do the intersection of road network and sunglare sites\n",
    "Find the intersected sunglare sites for each street segment. We need to set the buffer distance of 50 meters for each street segment considering the fact that the sunglare sites may not located on these road segments exactly.\n",
    "\n",
    "#### Using the split segments for building the rtree\n",
    "This uses the previous created road segments LineString list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_rtree_index = rtree.index.Index()\n",
    "\n",
    "for idx, element in enumerate(split_lines):\n",
    "    segments_rtree_index.insert(idx, element.buffer(50).bounds)\n",
    "# segments_rtree_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the segment_records can record the attribute of the intersected feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_rtree_index = rtree.index.Index()\n",
    "\n",
    "for idx, element in enumerate(segment_records):\n",
    "    ele_geom = element['line']\n",
    "    segments_rtree_index.insert(idx, ele_geom.buffer(50).bounds)\n",
    "# segments_rtree_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the segment rtree for the intersection analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use a dictionary to store the intersected point features\n",
    "segments_with_records = {}\n",
    "\n",
    "for record in glare_records:\n",
    "    record_pnt = record['point']\n",
    "    \n",
    "    # use rtree index to find the intersected roads\n",
    "    inter_roads = segments_rtree_index.intersection(record_pnt.bounds)\n",
    "    road_id_inter = [(segment_id, split_lines[segment_id].distance(record_pnt)) for segment_id in inter_roads]\n",
    "    \n",
    "    \n",
    "    # find the neareast pnts\n",
    "    if len(road_id_inter):\n",
    "        nearest = min(road_id_inter, key=lambda tup: tup[1])\n",
    "        segment_id = nearest[0]\n",
    "        \n",
    "        # create an empty list to store the sunglare records for all street segments\n",
    "        if segment_id not in segments_with_records:\n",
    "            segments_with_records[segment_id] = []\n",
    "        \n",
    "        segments_with_records[segment_id].append(record)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_with_records.get(1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "len(segments_with_records)\n",
    "print segments_with_records.get(0) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the intersection result, calculating the results for each street segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "outputShp = os.path.join(root, 'sunglare_AllRoads.shp')\n",
    "schema = {\n",
    "    'geometry': 'LineString',\n",
    "    'properties': {\n",
    "        'RouteNum': 'str:50',\n",
    "        'setdur': 'int',\n",
    "        'risedur': 'int',\n",
    "        'setglare': 'int',\n",
    "        'riseglare': 'int'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "with fiona.open(outputShp, 'w', driver=\"ESRI Shapefile\", schema=schema, crs=crs) as output:\n",
    "    for idx, segment in enumerate(split_lines):\n",
    "#     for idx, segment in enumerate(segment_records):\n",
    "#         segment_routeNo = segment['RouteNum']\n",
    "#         segment_geom = segment['line']\n",
    "        segment_geom = segment\n",
    "        \n",
    "        records = segments_with_records.get(idx)\n",
    "        \n",
    "        if records is None: \n",
    "            continue\n",
    "        elif len(records) < 6:\n",
    "            continue\n",
    "        \n",
    "        # create empty list of the sunrise and sunset glare\n",
    "        setdur_list = []\n",
    "        risedur_list = []\n",
    "        riseglare = []\n",
    "        setglare = []\n",
    "        \n",
    "        # loop the records to calculate the mean sunglare duration\n",
    "        for record in records:\n",
    "            risedur_list.append(record['risedur'])\n",
    "            setdur_list.append(record['setdur'])\n",
    "\n",
    "            # if there is no rise or set glare, the rise and set glare time is 0\n",
    "            if record['riseglare'] == 'None' or len(record['riseglare']) < 10:\n",
    "                riseglareTime = 0\n",
    "            else:\n",
    "                riseglareTime = int(record['riseglare'].split(',')[0].split('[')[1])\n",
    "\n",
    "            if record['setglare'] == 'None' or len(record['setglare']) < 10:\n",
    "                setglareTime = 0\n",
    "            else:\n",
    "                setglareTime = int(record['setglare'].split(',')[0].split('[')[1])\n",
    "\n",
    "            riseglare.append(riseglareTime)\n",
    "            setglare.append(setglareTime)\n",
    "\n",
    "\n",
    "        # calculate the mean starting point of the sunrise and sunset glare\n",
    "        riseglareT = np.median(np.asarray(riseglare))\n",
    "        setglareT = np.median(np.asarray(setglare))\n",
    "\n",
    "        # calcualte the mean value of the sunset and sunrise duration\n",
    "        setdurArr = np.asarray(setdur_list)\n",
    "        risedurArr = np.asarray(risedur_list)\n",
    "        setdur = np.median(setdurArr)\n",
    "        risedur = np.median(risedurArr)\n",
    "        \n",
    "        \n",
    "        # the data of the record\n",
    "        data = {\n",
    "            'RouteNum': 'segment_routeNo',\n",
    "            'setdur': setdur,\n",
    "            'risedur': risedur,\n",
    "            'setglare': setglareT,\n",
    "            'riseglare': riseglareT\n",
    "        }\n",
    "        \n",
    "        # write to the output shapefile\n",
    "        output.write({\n",
    "            'geometry': mapping(segment_geom),\n",
    "            'properties': data\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "outputShp = os.path.join(root, 'sunglare_AllRoads.shp')\n",
    "schema = {\n",
    "    'geometry': 'LineString',\n",
    "    'properties': {\n",
    "        'RouteNum': 'str:50',\n",
    "        'setdur': 'int',\n",
    "        'risedur': 'int',\n",
    "        'setglare': 'int',\n",
    "        'riseglare': 'int'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "with fiona.open(outputShp, 'w', driver=\"ESRI Shapefile\", schema=schema, crs=crs) as output:\n",
    "#     for idx, segment in enumerate(split_lines):\n",
    "    for idx, segment in enumerate(segment_records):\n",
    "        segment_routeNo = segment['RouteNum']\n",
    "        segment_geom = segment['line']\n",
    "        \n",
    "        records = segments_with_records.get(idx)\n",
    "        \n",
    "        # create empty list of the sunrise and sunset glare\n",
    "        setdur_list = []\n",
    "        risedur_list = []\n",
    "        riseglare = []\n",
    "        setglare = []\n",
    "        \n",
    "        try:\n",
    "            # loop the records to calculate the mean sunglare duration\n",
    "            for record in records:\n",
    "                risedur_list.append(record['risedur'])\n",
    "                setdur_list.append(record['setdur'])\n",
    "\n",
    "                # if there is no rise or set glare, the rise and set glare time is 0\n",
    "                if record['riseglare'] == 'None' or len(record['riseglare']) < 10:\n",
    "                    riseglareTime = 0\n",
    "                else:\n",
    "                    riseglareTime = int(record['riseglare'].split(',')[0].split('[')[1])\n",
    "                \n",
    "                if record['setglare'] == 'None' or len(record['setglare']) < 10:\n",
    "                    setglareTime = 0\n",
    "                else:\n",
    "                    setglareTime = int(record['setglare'].split(',')[0].split('[')[1])\n",
    "                \n",
    "                riseglare.append(riseglareTime)\n",
    "                setglare.append(setglareTime)\n",
    "                \n",
    "            \n",
    "            # calculate the mean starting point of the sunrise and sunset glare\n",
    "            riseglareT = np.median(np.asarray(riseglare))\n",
    "            setglareT = np.median(np.asarray(setglare))\n",
    "            \n",
    "            # calcualte the mean value of the sunset and sunrise duration\n",
    "            setdurArr = np.asarray(setdur_list)\n",
    "            risedurArr = np.asarray(risedur_list)\n",
    "            setdur = np.median(setdurArr)\n",
    "            risedur = np.median(risedurArr)\n",
    "            \n",
    "            \n",
    "            # the data of the record\n",
    "            data = {\n",
    "                'RouteNum': 'segment_routeNo',\n",
    "                'setdur': setdur,\n",
    "                'risedur': risedur,\n",
    "                'setglare': setglareT,\n",
    "                'riseglare': riseglareT\n",
    "            }\n",
    "            \n",
    "            # write to the output shapefile\n",
    "            output.write({\n",
    "                'geometry': mapping(segment_geom),\n",
    "                'properties': data\n",
    "            })\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup of the runing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13890"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "outputShp = os.path.join(root, 'sunglare_interstates.shp')\n",
    "schema = {\n",
    "    'geometry': 'LineString',\n",
    "    'properties': {\n",
    "        'setdur': 'int',\n",
    "        'risedur': 'int',\n",
    "        'setglare': 'str:250',\n",
    "        'riseglare': 'str:250'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "with fiona.open(streetMap, 'r') as road_segments:\n",
    "    crs = road_segments.crs\n",
    "    \n",
    "    with fiona.open(outputShp, 'w', driver=\"ESRI Shapefile\", schema=schema, crs=crs) as output:\n",
    "        \n",
    "        for idx, segment in enumerate(road_segments):\n",
    "            records = segments_with_records.get(idx)\n",
    "            \n",
    "            # create empty list of the sunrise and sunset glare\n",
    "            setdur_list = []\n",
    "            risedur_list = []\n",
    "            \n",
    "            try:\n",
    "                # loop the records to calculate the mean sunglare duration\n",
    "                for record in records:\n",
    "                    risedur_list.append(record['risedur'])\n",
    "                    setdur_list.append(record['setdur'])\n",
    "\n",
    "                # calcualte the mean value of the sunset and sunrise duration\n",
    "                setdurArr = np.asarray(setdur_list)\n",
    "                risedurArr = np.asarray(risedur_list)\n",
    "                setdur = np.median(setdurArr)\n",
    "                risedur = np.median(risedurArr)\n",
    "                \n",
    "                # the data of the record\n",
    "                data = {\n",
    "                    'setdur': setdur, \n",
    "                    'risedur': risedur,\n",
    "                    'setglare': 'sdfa',\n",
    "                    'riseglare': 'asdfa'\n",
    "                }\n",
    "\n",
    "                # write to the output shapefile\n",
    "                output.write({\n",
    "                    'geometry': mapping(shape(segment['geometry'])),\n",
    "                    'properties': data\n",
    "                })\n",
    "            \n",
    "            except:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_yaw = np.median(np.asarray(yaw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create r-tree index of the sunglare sites\n",
    "glare_rtree_index = rtree.index.Index()\n",
    "with fiona.open(sunglareMap) as glares:\n",
    "    for fid, glare in glares.items():\n",
    "        glare_geom = shape(glare['geometry']).buffer(50).bounds\n",
    "        glare_rtree_index.insert(fid, glare_geom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample code of previous script to find the nearby GSV panos for each crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the closest GSV points for each accident site\n",
    "# June 6th, 2018, Done\n",
    "\n",
    "import fiona\n",
    "from fiona.crs import to_string\n",
    "import rtree\n",
    "from shapely.geometry import shape\n",
    "import collections\n",
    "\n",
    "root = r'/Users/senseablecity/Dropbox (MIT)/ResearchProj/SunGlare/NationalScale-sunglare/accident data/FL'\n",
    "\n",
    "# the traffic accident map\n",
    "accidentShp = os.path.join(root, 'On2013.shp')\n",
    "reproj_metaShp = os.path.join(root, 'reproj_GSVpanoSite.shp')\n",
    "outputAccidentMap = os.path.join(root, 'On2013_gsvpano.shp')\n",
    "\n",
    "\n",
    "# open the accident and the gsv panorama\n",
    "with fiona.open(accidentShp, 'r') as acc_lyr:\n",
    "    accSchema = acc_lyr.schema\n",
    "    \n",
    "    with fiona.open(reproj_metaShp, 'r') as meta_lyr:\n",
    "        gsvSchema = meta_lyr.schema\n",
    "        print('The crs of the metagsv is:', meta_lyr.crs)\n",
    "        \n",
    "        # create an empty spatial index object\n",
    "        index = rtree.index.Index()\n",
    "        metaPntList = []\n",
    "        \n",
    "        # populate the spatial index, the polygon features\n",
    "        for fid, feat_meta in meta_lyr.items():\n",
    "            geom_meta = shape(feat_meta['geometry'])\n",
    "            coord = feat_meta['geometry']['coordinates']\n",
    "            geotype = feat_meta['geometry']['type']\n",
    "            \n",
    "            # get 2 feet buffer for each GSV point for the spatial operation\n",
    "            geo_meta_buffer = geom_meta.buffer(2)\n",
    "            index.insert(fid, geo_meta_buffer.bounds)\n",
    "            \n",
    "        print('You have build the R-tree successfully')\n",
    "        \n",
    "        schema = accSchema.copy()\n",
    "        schema['properties']['pntNum'] = 'str:80'\n",
    "        schema['properties']['panoID'] = 'str:80'\n",
    "        schema['properties']['longitude'] = 'str:80'\n",
    "        schema['properties']['month'] = 'str:80'\n",
    "        schema['properties']['year'] = 'str:80'\n",
    "        schema['properties']['latitude'] = 'str:80'\n",
    "        schema['properties']['yaw'] = 'float:24.15'\n",
    "        \n",
    "        crs = acc_lyr.crs\n",
    "        driver = acc_lyr.driver\n",
    "        \n",
    "        with fiona.open(outputAccidentMap, 'w', driver = driver, schema=schema, crs = crs) as out_acc_lyr:\n",
    "            \n",
    "            # loop all point features for calculating the nearest point\n",
    "            i = 0\n",
    "            for feat_acc in acc_lyr:\n",
    "                i = i + 1\n",
    "                if i % 1000 == 0: print ('You are runing to:', i)\n",
    "                geom_acc = shape(feat_acc['geometry'])\n",
    "                geom_acc_buffer = geom_acc.buffer(200)\n",
    "                \n",
    "                # use the R-tree index to find the intersected points from the potential area defined by the r-tree algorithm\n",
    "                nearby_gsv = index.intersection(geom_acc_buffer.bounds)\n",
    "                gsv_id_with_distance = [(gsv_id, shape(meta_lyr[gsv_id]['geometry']).distance(geom_acc)) for gsv_id in nearby_gsv]\n",
    "                \n",
    "                gsv_with_records = {}\n",
    "                \n",
    "                if len(gsv_id_with_distance):\n",
    "                    nearest = min(gsv_id_with_distance, key=lambda tup: tup[1])\n",
    "                    gsv_id = nearest[0]\n",
    "                    gsvProp = meta_lyr[gsv_id]['properties']\n",
    "                    \n",
    "                    feat_acc['properties'] = collections.OrderedDict(feat_acc['properties'].items() + gsvProp.items())\n",
    "                    out_acc_lyr.write(feat_acc)\n",
    "                    \n",
    "# #                     if gsv_id not in gsv_with_records:\n",
    "# #                         gsv_with_records[gsv_id] = []\n",
    "# #                     gsv_with_records[gsv_id].append(feat_acc)\n",
    "                    \n",
    "#                 print ('The gsv_with_records is:----------------', gsv_with_records)\n",
    "#                 panoid = feat_acc['properties']['KEYFIELD1']\n",
    "                \n",
    "#                 print('The length of the gsv_id_with_distance is:', panoid, len(gsv_id_with_distance))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
